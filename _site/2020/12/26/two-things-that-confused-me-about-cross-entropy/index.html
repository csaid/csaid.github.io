<!DOCTYPE html>
<html lang="en-us">

<!--
It's bad to import d3 in every post separately (https://groups.google.com/forum/#!topic/d3-js/bwdNirt2uEU).
Importing it globally here.
Putting this up at the top, according to this controversial stack overflow answer
http://stackoverflow.com/questions/7169370/d3-js-and-document-onready
 -->
<script src="https://d3js.org/d3.v5.min.js"></script>

<link rel="stylesheet" href="/public/font-awesome-4.4.0/css/font-awesome.min.css">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  
    <meta name="description" content="Some warnings about unstandardized notation">
  

  <!-- To get a link preview image, just set the image attribute in your _post -->
  
    <meta content="http://localhost:4000/assets/2020_cross_entropy/H_p_q.png" property="og:image"/>
  

  <!-- twitter standard -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@chris_said" />
  <meta name="twitter:title" content="Two things that confused me about cross-entropy" />
  <meta name="twitter:description" content="Some warnings about unstandardized notation" />


  <title>
    
      Two things that confused me about cross-entropy &middot; Chris Said
    
  </title>

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-67746868-1', 'auto');
    ga('send', 'pageview');
  </script>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

<!--   <body class="theme-base-cps">
 -->
  <body>

    <div class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Chris Said
        </a>
      </h1>
      <p class="lead">I am a data scientist at Stitch Fix. This blog is mostly about statistics, technology, and science.</p>

    </div>

    <nav class="sidebar-nav">

      
        <a class="sidebar-nav-item" href="/">Home</a>
      
        <a class="sidebar-nav-item" href="/atom.xml">Feed</a>
      

    </nav>

    <div class="wrapper">
      <div class="inner">
        <a href = "http://www.twitter.com/Chris_Said" class="contact-button"><i class="fa fa-twitter fa-2x"></i></a>
        <a href = "https://www.linkedin.com/pub/chris-said/6b/86b/979" class="contact-button"><i class="fa fa-linkedin-square fa-2x"></i></a>
        <a href = "mailto:chris.said@gmail.com" class="contact-button"><i class="fa fa-envelope fa-2x"></i></a>
      </div>
    </div>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Two things that confused me about cross-entropy</h1>
  <span class="post-date">26 Dec 2020</span>
  <p>Every once in a while, I try to better understand cross-entropy by skimming over some Medium posts and StackExchange answers. I always come away only half-understanding it.</p>

<p>A major cause of confusion is that different sources use different notations and conventions. Here are two that have tripped me up.</p>

<h3 id="p-and-q-vs-y-and-p">p and q vs y and p</h3>

<p>In information theory, the cross-entropy for an event with \(M\) discrete outcome classes is</p>

\[H(p, q) = -\sum_{j=1}^M{p_j log (q_j)}\]

<p>… where \(p\) is the true distribution of outcomes and \(q\) is the approximating distribution.</p>

<p>But in machine learning, the cross-entropy is defined as:</p>

\[H(y, p) = -\sum_{j=1}^M{y_j log (p(y_j))}\]

<p>… where \(y\) are the true labels and \(p(y)\) is the approximating distribution, i.e. the classifier’s probability predictions.</p>

<p>Notice that the meaning of \(p\) has been reversed! In information theory, it is the true distribution. In machine learning, it is the approximating distribution.</p>

<p>This points to a key difference between generic information theory and machine learning applications. In information theory, the target distribution \(p\) is a probability distribution where the probability mass can be distributed broadly over the classes. In machine learning, the target distribution \(y\) has all of its mass allocated to a known label.</p>

<h3 id="multiple-classes-vs-multiple-trials">Multiple classes vs multiple trials</h3>

<p>As shown above, the cross-entropy for a single event with \(M\) classes is:</p>

\[H(y, p) = -\sum_{j=1}^M{y_j log (p(y_j))}\]

<p>If there are multiple trials, you just need to sum up the cross-entropies from all the trials so that the total cross-entropy is:</p>

\[H(y, p) = -\sum_{i=1}^N \sum_{j=1}^M{y_j^{(i)} log (p(y_j^{(i)}))}\]

<p>… where \(N\) is the number of trials.</p>

<p>This all makes notational sense. Unfortunately, confusion arises when people use non-compact notation for summing over binary classes. When dealing with binary classification, it’s common to see cross-entropy defined as:</p>

\[H(y, p) = -\sum_{i=1}^N{y_i log (p(y_i)) + (1-y_i) log (1 -p(y_i))}\]

<p>Superficially, this looks a lot like the first formula, but it’s actually just a clever way of writing the second formula for binary classes. The first and third formulas confusingly look very similar, but the confusion goes away when you realize the two summation signs mean different things. One sums over classes, while the other sums over trials.</p>

<p>The image below shows these two formulas broken into their components.</p>

<p><img src="/assets/2020_cross_entropy/cross-entropy.png" /></p>

<h3 id="where-to-learn-about-cross-entropy">Where to learn about cross-entropy</h3>
<p>I don’t know if there is a single best place to learn about cross-entropy, but below are a few places that were helpful. If you read them make sure you think about (a) which notation they are using (b) whether they are writing about single trials or multiple trials and (c) whether they are writing about binary classes or multi classes.</p>

<ul>
  <li><a href="https://xcelab.net/rm/statistical-rethinking">Statistical Rethinking</a>. Information theory notation, single trial case, multiple classes.</li>
  <li><a href="http://www.awebb.info/probability/2017/05/18/cross-entropy-and-log-likelihood.html">Andrew Webb</a>. Both notations, both the single and multiple trial case, multiple classes.</li>
  <li><a href="https://towardsdatascience.com/log-loss-function-math-explained-5b83cd8d9c83">Harshith</a>. ML notation, multiple trials, binary classes.</li>
</ul>


  <div>
    <a class="twitter-share-button"
      href="https://twitter.com/share"
      data-url=""
      data-via="Chris_Said"
      data-size="large"
      data-count="none">
    Tweet
    </a>
</div>

  <div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'csaid81';
    var disqus_identifier = 'http://localhost:4000/2020/12/26/two-things-that-confused-me-about-cross-entropy/';
    var disqus_url = 'http://localhost:4000/2020/12/26/two-things-that-confused-me-about-cross-entropy/';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

</div>


    </div>

  </body>
</html>

<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

<script>window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));</script>
